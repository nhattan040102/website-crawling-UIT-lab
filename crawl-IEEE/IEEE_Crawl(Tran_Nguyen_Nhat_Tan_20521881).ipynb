{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IEEE_Crawl(Tran_Nguyen_Nhat_Tan-20521881).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OZ9CgxcJahtw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import thư viện để crawl dữ liệu từ website <Ở đây là IEEE Xplore> (Dùng selenium, beautifulsoup lib của python)"
      ],
      "metadata": {
        "id": "OZ9CgxcJahtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "bpTSBohNRgQh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC947Zz1MPnI",
        "outputId": "58ce3124-2e58-402c-8b0c-21c4949ecebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.3)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.20.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.8)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (36.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (99.0.4844.51-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By"
      ],
      "metadata": {
        "id": "GrWREDpLdyro"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time"
      ],
      "metadata": {
        "id": "WEzVedzlk7dR"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tạo chương trình để người dùng nhập tên tác giả mà muốn crawl dữ liệu từ trang IEEE Xplore"
      ],
      "metadata": {
        "id": "XVcSZL-Ga4OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up selenium in google collab\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c9ebEJJa3Xr",
        "outputId": "e2b8788e-4a48-4c2c-8fd6-62c6a3c13823"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ket noi voi trang chu cua website ieeexplore\n",
        "driver.get(\"https://ieeexplore.ieee.org/Xplore/home.jsp\")"
      ],
      "metadata": {
        "id": "bmJyU_B8NBv0"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tim thanh tim kiem cua website để nhập tên\n",
        "search_bar = driver.find_element(By.CSS_SELECTOR, \"input[aria-label='Enter search text']\")\n",
        "\n",
        "# Nguoi dung nhap ten cua tac gia can tim kiem\n",
        "author = input(\"Nhap ten tac gia ma ban muon tim bai bao khoa hoc: \")\n",
        "\n",
        "# Nhap ten ma nguoi dung vua nhap vao thanh tim kiem \n",
        "search_bar.clear()\n",
        "search_bar.send_keys(author)\n",
        "search_bar.send_keys(Keys.RETURN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXetTo3pe9lG",
        "outputId": "ca270485-e415-4231-e3eb-a60430595014"
      },
      "execution_count": 134,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nhap ten tac gia ma ban muon tim bai bao khoa hoc: Duy Dinh Le\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Luu anh tim kiem ten tac gia vao bo nho\n",
        "driver.save_screenshot('WebsiteScreenShot.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrTUreX5Oz7O",
        "outputId": "cdce34c9-9a5f-4d3e-e1c9-1916debffccc"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tìm dữ liệu mong muốn để lấy, ở đây chúng ta sẽ tìm những dữ liệu như sau:\n",
        " 1. Journal_title\n",
        " 2. Authors\n",
        " 3. Published_events\n",
        " 4. Published_years \n",
        " 5. Conference_locations \n",
        " 6. Contents "
      ],
      "metadata": {
        "id": "laToIiOpbWMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Journal_title = \"\"\n",
        "Authors = \"\"\n",
        "Published_events = \"\"\n",
        "Published_years = \"\"\n",
        "Conference_locations = \"\"\n",
        "Contents = \"\""
      ],
      "metadata": {
        "id": "SeSa32suap6T"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number = 1\n",
        "url = \"https://ieeexplore.ieee.org/search/searchresult.jsp?newsearch=true&queryText=Duy%20Dinh%20Le\"\n",
        "\n",
        "with open(f\"Scientific_journals_data.txt\", \"w\") as file:\n",
        "  for page_num in range(1, 4):\n",
        "# Dung beautifulsoup de bat dau crawl data\n",
        "    link = url + f'&highlight=true&returnFacets=ALL&returnType=SEARCH&matchPubs=true&pageNumber={page_num}'\n",
        "    driver.get(link)\n",
        "    time.sleep(10)\n",
        "    soup_file=driver.page_source\n",
        "    soup = BeautifulSoup(soup_file)\n",
        "    results = soup.find_all('div', class_=\"col result-item-align\")\n",
        "    \n",
        "    for result in results:\n",
        "      detailed_link = 'https://ieeexplore.ieee.org' + str(result.h2.a['href']) + 'authors#authors'\n",
        "      driver.get(detailed_link)\n",
        "      time.sleep(10)\n",
        "      soup = BeautifulSoup(driver.page_source)\n",
        "\n",
        "      Journal_title = soup.find('h1', class_=\"document-title text-2xl-md-lh\").text\n",
        "      Contents = soup.find('div', class_=\"abstract-text row\").text.replace(\"Abstract:\", ' ').replace('.', '.\\n')\n",
        "      Published_events = soup.find('div', class_=\"u-pb-1 stats-document-abstract-publishedIn\")\n",
        "      Conference_locations = soup.find('div', class_=\"u-pb-1 doc-abstract-conferenceLoc\")\n",
        "      Published_years = soup.find('div', class_=\"u-pb-1 doc-abstract-confdate\")\n",
        "      for author in soup.find_all('div', class_=\"authors-accordion-container\"):\n",
        "        Authors = str(author.a.text)  + ' | ' + Authors \n",
        "\n",
        "      file.write(f\"----  Scientific journal number {number}  ----\")\n",
        "      file.write(f\"\\nTitle: {Journal_title} \")\n",
        "      file.write(f\"\\nAuthor: {Authors} \")\n",
        "      if Published_years != None:\n",
        "        file.write(f\"\\n{Published_years.text}\")\n",
        "      if Published_events != None:\n",
        "        file.write(f\"\\n{Published_events.text}\")\n",
        "      if Conference_locations != None:\n",
        "        file.write(f\"\\n{Conference_locations.text}\")\n",
        "      file.write(f\"\\nContent:\\n{Contents}\\n\\n\")\n",
        "      number = number + 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eQjslyISRetI"
      },
      "execution_count": 139,
      "outputs": []
    }
  ]
}